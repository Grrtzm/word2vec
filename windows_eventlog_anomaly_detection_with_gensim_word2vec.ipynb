{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b4ec9568",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92\">\n",
    "    <img src=\"https://github.com/Grrtzm/word2vec/blob/main/tds.png\" />\n",
    "    View Zhi Li's Gensim Word2Vec tutorial on 'Towards Data Science'</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Grrtzm/word2vec/blob/main/windows_eventlog_anomaly_detection_with_gensim_word2vec.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run this notebook in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/Grrtzm/word2vec/blob/main/windows_eventlog_anomaly_detection_with_gensim_word2vec.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/zhlli1/Genism-word2vec/blob/master/Genism%20Word2Vec%20Tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download original Word2Vec tutorial notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee66d3b",
   "metadata": {},
   "source": [
    "# Word2Vec on Windows Eventlogs\n",
    "This notebook is part of a project that uses Word2Vec for anomaly detection in Windows 10 event logs.<br>\n",
    "It uses a dataset which consists of all events derived from the System event log from my own PC.<br>\n",
    "The data was read using Powershell and Get-WinEvent. You can find the Powershell script and the python script for parsing in my github repository.<br>\n",
    "This version uses the Gensim implementation of Word2Vec, <a target=\"_blank\" href=\"https://colab.research.google.com/github/Grrtzm/word2vec/blob/main/windows_eventlog_anomaly_detection_with_tensorflow_word2vec.ipynb\">this version uses a Tensorflow implementation of Word2Vec</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad6ded7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "# from time import time  # To time our operations\n",
    "from datetime import datetime # For DateTime -> date operations\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Word2Vec hyperparameters:\n",
    "# num_ns: Set the number of negative samples per positive context.\n",
    "# num_ns: between [5, 20] is shown to work best for smaller datasets, while num_ns between [2,5] suffices for larger datasets.\n",
    "num_ns = 5\n",
    "window_size = 5\n",
    "embedding_dim = 20 #  20 seems to be sufficient, 128 is the default value from the tutorial   # Dimension of the dense embedding.\n",
    "vocab_size = 20000 # inital size of the vocabulary. We will resize it later before defining the model.\n",
    "# sequence_length = 40 # Number of words in a sentence.\n",
    "epochs = 1000 # Number of training epochs for Word2Vec\n",
    "\n",
    "# df = pd.read_csv('D:\\logs\\AllEvents-sorted.csv', parse_dates=[\"TimeCreated\"]) \n",
    "df = pd.read_csv('D:/logs/winevt/20211202/System-Events-custom.csv', parse_dates=[\"TimeCreated\"]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6ab33",
   "metadata": {},
   "source": [
    "## Create Event \"word\" from multiple columns\n",
    "This creates a new column containing the words Word2Vec will be trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punct = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{}~'   # `|` is not present here\n",
    "transtab = str.maketrans(dict.fromkeys(punct, ''))\n",
    "\n",
    "# Define a function to remove spaces\n",
    "# Source: https://iqcode.com/code/python/pandas-series-remove-punctuation\n",
    "# and https://stackoverflow.com/questions/50444346/fast-punctuation-removal-with-pandas\n",
    "def remove_spaces(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(' ', '')\n",
    "    return text\n",
    "\n",
    "# Create a new column. Concatenate the columns, remove unwanted characters and convert to lowercase\n",
    "df['Event'] = df['EventID'].map(str) + df['Level'].map(str) + df['Provider'].apply(remove_spaces).map(str)\n",
    "df['Event'] = '|'.join(df['Event'].tolist()).translate(transtab).split('|') # remove all other unwanted characters\n",
    "df['Event'] = df['Event'].str.lower()\n",
    "\n",
    "# Delete the redundant columns\n",
    "df = df.drop(['EventID','Level','Provider'], axis=1)\n",
    "\n",
    "# Change order of columns by name, so we can display it orderly\n",
    "df = df[['TimeCreated', 'EventRecordID', 'Event', 'Message']]\n",
    "\n",
    "# Show a preview\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(df.axes[0])\n",
    "print(f\"Number of lines/events in the dataset: {num_rows}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8db95",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da3837",
   "metadata": {},
   "source": [
    "Since the purpose of this tutorial is to learn how to generate word embeddings using genism library, I will not do the EDA and feature selection for the word2vec model for the sake of simplicity. \n",
    "<br> \n",
    "Gensim word2Vec requires that a format of list of list for training where every document is contained in a list and every list contains list of tokens of that document. At first, we need to generate a format of list of list for training the make model word embedding. To be more specific, each make model is contained in a list and every list contains list of features of that make model.\n",
    "To achieve these, we need to do the following data preprocessing steps :\n",
    "1. Create a new column for Make Model \n",
    "2. Generate a format of list of list for each Make Model with the following features: Engine Fuel Type, Transmission Type, Driven_Wheels, Market Category, Vehicle Size and Vehicle Style. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebf312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier creÃ«er ik een tekst dataset eventlist, een list van lists. De list eventrow is gevuld met alle events van die dag.\n",
    "# Zie ook blokje [8] van lees-data-v3\n",
    "eventlist = []\n",
    "eventrow = []\n",
    "previous_date = None # datetime.now().date()\n",
    "for idx, row in df.iterrows():\n",
    "    date = row['TimeCreated'].date()\n",
    "    eventrow.append(row['Event'])\n",
    "    if date != previous_date:\n",
    "        eventrow = []\n",
    "        eventlist.append(eventrow)\n",
    "        previous_date = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(eventlist))\n",
    "# print()\n",
    "# print(eventlist[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ad2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the Gensim word2vec model with our own custom corpus\n",
    "\n",
    "# Skip-gram:\n",
    "model = Word2Vec(eventlist, min_count=1, vector_size=20, workers=8, window=3, sg=1, epochs=1000) #, compute_loss=True) #, callbacks=[epoch_logger])\n",
    "\n",
    "# CBOW:\n",
    "# model = Word2Vec(eventlist, min_count=1, vector_size=20, workers=8, window=3, sg=0, epochs=1000, hs=1, negative=0) #, compute_loss=True) #, callbacks=[epoch_logger])\n",
    "\n",
    "word_vectors = model.wv\n",
    "word_vectors.save('vectors.kv')\n",
    "reloaded_word_vectors = KeyedVectors.load('vectors.kv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3fb16",
   "metadata": {},
   "source": [
    "Reference: https://radimrehurek.com/gensim/models/word2vec.html and https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\n",
    "Apparently, Gensim v4.0 was released on 31-3-2021\n",
    "\n",
    "Let's try to understand the hyperparameter of this model.\n",
    "1. vector_size: The number of dimensions of the embeddings and the default is 100.\n",
    "2. window: The maximum distance between a target word and words around the target word. The default window is 5.\n",
    "3. min_count: The minimum count of words to consider when training the model; words with occurrence less than this count will be ignored. The default for min_count is 5.\n",
    "4. workers: The number of partitions during training and the default workers is 3. \n",
    "5. sg: The training algorithm, either CBOW(0) or skip gram (1). The default training alogrithm is CBOW. \n",
    "6. epochs: number of training cycles\n",
    "7. hs: 0, 1   1=hierarchical softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071fef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://radimrehurek.com/gensim/models/keyedvectors.html#module-gensim.models.keyedvectors\n",
    "# distances(word_or_vector, other_words=())\n",
    "# Compute cosine distances from given word or vector to all words in other_words. If other_words is empty, return distance between word_or_vectors and all words in vocab.\n",
    "\n",
    "print(f\"Number of words in internal Word2Vec vocabulary: {len(model.wv)}\")\n",
    "print(model.wv.get_vector('system137errorntfs', norm=True))\n",
    "print()\n",
    "print(model.wv.similarity('system136warningntfs','system137errorntfs'))\n",
    "print()\n",
    "print(model.wv.distance('system136warningntfs','system137errorntfs'))\n",
    "print()\n",
    "print(model.wv.distances('system137errorntfs', other_words=([\"system26informationapplicationpopup\",\"system51warningdisk\"])))\n",
    "print()\n",
    "print(model.wv.distance('system137errorntfs','system26informationapplicationpopup'))\n",
    "print()\n",
    "print(model.wv.distance('system137errorntfs','system7040informationservicecontrolmanager'))\n",
    "print()\n",
    "print(model.wv.rank_by_centrality(['system51warningdisk','system137errorntfs'], use_norm=True))\n",
    "print()\n",
    "\n",
    "#print(model.wv['system18informationbthusb']) # Foutmelding: KeyError: \"Key 'system18informationbthusb' not present\"\n",
    "# print(model.wv.most_similar('system136warningntfs')) # Foutmelding: KeyError: \"Key 'system18informationbthusb' not present\"\n",
    "# print()\n",
    "# print(model.wv.get_vector('system136warningntfs', norm=True))\n",
    "# print()\n",
    "# print(model.wv.evaluate_word_pairs('system136warningntfs','system137errorntfs')) # Dit werkt niet; FileNotFoundError: [Errno 2] No such file or directory: 'system136warningntfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38cd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = len(df.axes[0])\n",
    "# add empty columns\n",
    "cos_sim = []\n",
    "for idx, row in df.iterrows():\n",
    "    current_event = row['Event']\n",
    "    if idx == 0:\n",
    "        cos_sim.append(float(0))\n",
    "        previous_event = current_event\n",
    "    if idx > 0:\n",
    "        if idx < num_events + 1:\n",
    "            cs = model.wv.similarity(previous_event, current_event)\n",
    "            cos_sim.append(cs)\n",
    "            previous_event = current_event\n",
    "\n",
    "df['cos_sim'] = cos_sim\n",
    "\n",
    "# Change order of columns by name, so we can display it orderly\n",
    "df = df[['TimeCreated', 'EventRecordID', 'Event', 'cos_sim', 'Message']]\n",
    "df.head()\n",
    "\n",
    "# saving the dataframe\n",
    "df.to_csv('D:/logs/winevt/20211202/System-Events-dist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(200, 20))\n",
    "x = df['TimeCreated']\n",
    "y = df['cos_sim']\n",
    "line, = ax.plot(x, y)\n",
    "# Major ticks every month, minor ticks every day,\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
    "ax.grid(True, which='both', axis='both')\n",
    "# Text in the x axis will be displayed in 'YYYY-mm-dd' format.\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b-%d'))\n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%d'))\n",
    "# Rotates and right-aligns the x labels so they don't crowd each other.\n",
    "for label in ax.get_xticklabels(which='major'):\n",
    "    label.set(rotation=90, horizontalalignment='right')\n",
    "for label in ax.get_xticklabels(which='minor'):\n",
    "    label.set(rotation=90, horizontalalignment='right')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.savefig(\"cos_sim.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766330d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas display settings\n",
    "# Set it to None to display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width',200)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.colheader_justify','left')\n",
    "#df.style.set_properties(**{'text-align': 'left'})\n",
    "#df.style.set_properties(subset=['Event', 'Message'], **{'text-align': 'left'})\n",
    "\n",
    "#dfStyler = df.style.set_properties(**{'text-align': 'left'})\n",
    "#dfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "df.style.set_properties(**{'text-align': 'left'}).set_table_styles([ dict(selector='th', props=[('text-align', 'left')] ) ])\n",
    "\n",
    "print(\"Top 10 of all 'anomalies':\\n\")\n",
    "df.nsmallest(n=10, columns=['cos_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result to a file:\n",
    "# df.to_csv('D:/Machine_Learning/word2vec/file1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only display the rows containing 'critical'\n",
    "dfcritical = df[df['Event'].str.contains('critical')]\n",
    "print(f\"Number of 'critical' events: {len(dfcritical)}\\n\")\n",
    "print(\"Top 10 of 'critical' anomalies:\\n\")\n",
    "dfcritical.nsmallest(n=10, columns=['cos_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a279d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only display the rows containing 'error'\n",
    "dferror = df[df['Event'].str.contains('error')]\n",
    "print(f\"Number of 'error' events: {len(dferror)}\\n\")\n",
    "print(\"Top 10 of 'error' anomalies:\\n\")\n",
    "dferror.nsmallest(n=10, columns=['cos_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e46572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import search\n",
    "print(f\"   Index TimeCreated                      EventRecordID Event                                                        cos_sim\")\n",
    "for ind in dferror.index:\n",
    "    if not search('errortcpip', dferror['Event'][ind]):\n",
    "        if not search('system10010', dferror['Event'][ind]):\n",
    "            print(f\"{ind:8d} {dferror['TimeCreated'][ind]} {dferror['EventRecordID'][ind]:13d} {dferror['Event'][ind]:60s} {dferror['cos_sim'][ind]:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb8aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb691a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
